{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Generator model\n",
    "def build_generator(latent_dim, channels):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(256, input_dim=latent_dim))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Dense(1024))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Dense(np.prod(channels), activation='tanh'))\n",
    "    model.add(layers.Reshape((*channels,)))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Discriminator model\n",
    "def build_discriminator(image_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=image_shape))\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Combine generator and discriminator into a GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = keras.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "image_shape = (64, 64, 3)\n",
    "\n",
    "# Build and compile the models\n",
    "generator = build_generator(latent_dim, image_shape[-1])\n",
    "discriminator = build_discriminator(image_shape)\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5))\n",
    "\n",
    "\n",
    "# Training loop\n",
    "epochs = 10000\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Select a random batch of hand drawings\n",
    "    idx = np.random.randint(0, dataset.shape[0], batch_size)\n",
    "    real_images = dataset[idx]\n",
    "\n",
    "    # Generate a batch of digital drawings\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # Train the discriminator\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, np.ones((batch_size, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, np.zeros((batch_size, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train the generator (trying to make the discriminator classify generated images as real)\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch}/{epochs} - D loss: {d_loss[0]} - D accuracy: {100 * d_loss[1]}% - G loss: {g_loss}\")\n",
    "\n",
    "    # Optionally, save generated images at certain intervals\n",
    "    if epoch % save_interval == 0:\n",
    "        save_generated_images(epoch)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
